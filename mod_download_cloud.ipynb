{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Download_tobacco.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Kns7eDRLx-D7",
        "qSvL7SpZLvj-",
        "8IPYhT1VMS8_"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tqiaowen/LSTrAP-Cloud/blob/master/mod_download_cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71pqkH1owdoE",
        "colab_type": "text"
      },
      "source": [
        "##1. Download Script\n",
        "This script is based on the original download script found at https://github.com/wirriamm/CoNeGC/blob/master/1_Download_scripts_30Jan.ipynb, obtained on 30 January 2020.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd1c1s8M6Cy0",
        "colab_type": "text"
      },
      "source": [
        "# Getting started\n",
        "\n",
        "\n",
        "\n",
        "1.   Create folder that you want to work in on Google Drive\n",
        "2.   Download CDS file of the organism that you are working with into the folder\n",
        "3.   Create a file containint the list of SRA runIDs that you want to download\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH1vtXATwNSs",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Mount Google Drive\n",
        "\n",
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!rm -rf /content/sample_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kns7eDRLx-D7",
        "colab_type": "text"
      },
      "source": [
        "####Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5Rvuo_MK6Zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import modules\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime as dt\n",
        "import scipy.stats as stats\n",
        "import json\n",
        "import math\n",
        "import re\n",
        "import ast\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeEw40gnLj66",
        "colab_type": "text"
      },
      "source": [
        "####User input of variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHNkZjz85SkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Input form {display-mode: \"form\"}\n",
        "\n",
        "#@markdown Enter the species name in the format \"_**Genus_species**_\", Eg: '_**Elaeis_guineensis**_'\n",
        "\n",
        "#@markdown The folder name in your Google Drive main directory should also go by this name.\n",
        "\n",
        "species_name = 'Ntab' #@param {type: 'string'}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown File name for Run Table (with extension), stored in Google Drive folder.\n",
        "\n",
        "#@markdown Eg: '_**RunTable_Elaeis_guineensis.txt**_'\n",
        "\n",
        "RunTable_file = 'runid_Ntab.txt' #@param {type: 'string'}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown File name for CDS file (with extension), stored in Google Drive folder.\n",
        "\n",
        "#@markdown Eg: '_**cds.selected_transcript.egu.fasta.gz**_'\n",
        "\n",
        "cds_fasta_file = 'GCF_000715135.1_Ntab-TN90_cds_from_genomic.fna.gz' #@param {type: 'string'}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown Specify download mode\n",
        "\n",
        "download_mode = \"B. Continue from previous run\" #@param [\"A. Start fresh run\", \"B. Continue from previous run\"]\n",
        "download_mode = download_mode[0]\n",
        "\n",
        "if download_mode == \"B\":\n",
        "  Date_initiated = '2020-01-31' #@param {type: 'date'}\n",
        "  date = Date_initiated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSvL7SpZLvj-",
        "colab_type": "text"
      },
      "source": [
        "####Install Dependencies, Initialise Variables and Directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKhgpeyZLxJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Dependencies directory\n",
        "if os.path.exists('/content/Dependencies') == False:\n",
        "  os.mkdir('/content/Dependencies')\n",
        "  os.chdir('/content/Dependencies')\n",
        "  print('Dependencies directory created.')\n",
        "  #Download and install kallisto\n",
        "  os.system('wget \\'https://github.com/pachterlab/kallisto/releases/download/v0.46.0/kallisto_linux-v0.46.0.tar.gz\\'')\n",
        "  os.system('tar -xf kallisto_linux-v0.46.0.tar.gz')\n",
        "  if os.path.exists('kallisto/kallisto'):\n",
        "    print('kallisto installed.')\n",
        "    !cp kallisto/kallisto /bin/kallisto\n",
        "  else:\n",
        "    print('kallisto not found.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_bXo3YjLz3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define paths\n",
        "working_dir_path = \"/content/gdrive/My Drive/Projects/William_2019/\" + species_name + \"/\"\n",
        "working_dir_path_ter = \"/content/gdrive/My\\ Drive/Projects/William_2019/\" + species_name + \"/\"\n",
        "  #Note: \"\\(whitespace)\" is needed when we are calling shell command as a string via os.system\n",
        "RunTablePath = working_dir_path + RunTable_file\n",
        "cds_fasta_path = working_dir_path_ter + cds_fasta_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhFStAYYL5pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make new directory for this execution of the script if user chooses option \"A\"\n",
        "os.chdir(working_dir_path)\n",
        "\n",
        "if download_mode == \"A\":\n",
        "  date = str(dt.now().date())\n",
        "  files = os.listdir(working_dir_path)\n",
        "  try:\n",
        "      os.mkdir(working_dir_path + date + \"_01\")\n",
        "      print(date + \"_01 directory has been created.\") \n",
        "  except FileExistsError:\n",
        "      filename = max([filename for filename in files if date in filename])\n",
        "      file_serial_int = int(filename[-2:]) + 1\n",
        "      if 1 < file_serial_int < 10:\n",
        "          file_serial_str = \"0\" + str(file_serial_int)\n",
        "      elif 10 <= file_serial_int < 100:\n",
        "          file_serial_str = str(file_serial_int)\n",
        "          \n",
        "      os.mkdir(working_dir_path + date + \"_\" + file_serial_str)\n",
        "      print(date + \"_\" + file_serial_str + \" directory has been created.\")\n",
        "  except:\n",
        "      print(\"Directory failed to be created.\")\n",
        "\n",
        "#Calls the most recent directory\n",
        "#Will start from here for Option \"B\"\n",
        "files = os.listdir(working_dir_path)\n",
        "filename = max([filename for filename in files if date in filename])\n",
        "execution_dir_path = working_dir_path + filename + \"/\"\n",
        "execution_dir_path_ter = working_dir_path_ter + filename + \"/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dk6QbUrL9CZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download report\n",
        "#Create a tab-separated .txt logfile that stores time and progress in this workflow\n",
        "os.chdir(execution_dir_path)\n",
        "#species_name = (RunTablePath.split('/')[-1]).split('_',1)[1][:-4]\n",
        "download_report_name = \"Download_report_\" + species_name + \"_\" + date + \".txt\"\n",
        "\n",
        "if os.path.exists(download_report_name):\n",
        "  pass\n",
        "  #For Option B, Download report will be read later in the for loop\n",
        "\n",
        "else:\n",
        "  #Create new download report\n",
        "  download_report = open(download_report_name, \"a+\")\n",
        "  download_report.write(\"Run ID\\tLibrary Layout\\tStatus\\tFile size\\tTimestamp\\tKallisto time (s)\\tn_processed\\tn_pseudoaligned\\tp_pseudoaligned\\t%genes mapped\\n\")\n",
        "  download_report.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IplS1oKMB4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create kallisto index\n",
        "kallisto_index_path_ter = execution_dir_path_ter + \"index_file_\" + species_name #to be created by kallisto\n",
        "kallisto_index_path = execution_dir_path + \"index_file_\" + species_name\n",
        "\n",
        "if os.path.exists(kallisto_index_path):\n",
        "  print(\"Kallisto index already present for \" + species_name + \".\")\n",
        "else:\n",
        "  index_start = time.time()\n",
        "  # os.system(kallisto_path + \" index -i \" + kallisto_index_path_ter + \" \" + cds_fasta_path)\n",
        "  !kallisto index -i $kallisto_index_path_ter $cds_fasta_path\n",
        "  if os.path.exists(kallisto_index_path):\n",
        "    print(\"Kallisto index created for \" + species_name + \".\")\n",
        "    print(\"Time to create kallisto index:\", time.time()-index_start)\n",
        "  else:\n",
        "    print(\"Kallisto index not found for \" + species_name + \".\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IPYhT1VMS8_",
        "colab_type": "text"
      },
      "source": [
        "####Download functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ55RG81Etx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Functions#############################################################\n",
        "\n",
        "def get_ftp_links(RunID):\n",
        "  '''(str)->(str,str)\n",
        "  Return ftp link in the paired and unpaired format for the RunID specified\n",
        "  '''\n",
        "  dir2 = \"\"\n",
        "  if 9 < len(RunID) <= 12:\n",
        "      dir2 = \"0\"*(12 - len(RunID)) + RunID[-(len(RunID)-9):] + \"/\"\n",
        "  dirs = RunID[:6] + \"/\" + dir2 + RunID\n",
        "  ftp_link_paired = \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/\" + dirs + \"/\" + RunID + \"_1.fastq.gz\"\n",
        "  ftp_link_unpaired = \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/\" + dirs + \"/\" + RunID + \".fastq.gz\"\n",
        "  return ftp_link_paired, ftp_link_unpaired\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def dlsize(RunID):\n",
        "  \"\"\"(str)->(str)\n",
        "  Returns size of downloaded file obtained from the log\n",
        "  \"\"\"\n",
        "  ll= open(RunID +\".log\", \"r\").readlines()[-1].split(\" \")\n",
        "  con = []\n",
        "  for i in ll:\n",
        "    if i != '':\n",
        "      con.append(i)\n",
        "    if len(con) >= 4:\n",
        "      break\n",
        "  return con[-1]\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def kallisto_stream(RunID):\n",
        "  '''(str)->(float,str,str,str,str)\n",
        "  Runs kallisto quant on streamed fastq file for each RunID, streaming the unpaired file first. If streaming for unpaired file fails, streaming will be attempted for paired file.\n",
        "  If both streaming for unpaired and paired files are unsuccessful, i.e. curl: (78) RETR response: 550; file probably does not exist on server and subsequent attempts will be aborted.\n",
        "  For streaming (curl command):\n",
        "    Streams only the first 1M bytes of data.\n",
        "    Ensures that:\n",
        "      Download speed not < 1x10^9 Bytes for 30 s\n",
        "      Maximum time taken = 600 s = 10 min\n",
        "    If these speed/time are not met, download is terminated and restarted for a total of 3 tries.\n",
        "  '''\n",
        "  RunID_file_path = execution_dir_path + RunID + \"/\"\n",
        "  paired, unpaired = get_ftp_links(RunID)\n",
        "  layout = \"Layout unknown\"\n",
        "  for i in range(3): #try downloading at most 3 times\n",
        "    kallisto_start = time.time()\n",
        "    timestamp = datetime.datetime.now()\n",
        "    # Dl first 1m bytes, max time 600s, speed limit ~1gb for 30s, send stderr to RunID.log\n",
        "    if layout == \"Paired\":\n",
        "      !kallisto quant -i $kallisto_index_path_ter -o $RunID --single -l 200 -s 20 -t 2 <(curl -L -r 0-1000000000 -m 600 --speed-limit 1000000 --speed-time 30 $paired 2> $RunID'.log')\n",
        "    else:\n",
        "      !kallisto quant -i $kallisto_index_path_ter -o $RunID --single -l 200 -s 20 -t 2 <(curl -L -r 0-1000000000 -m 600 --speed-limit 1000000 --speed-time 30 $unpaired 2> $RunID'.log')\n",
        "      if 'curl: (78)' not in open(RunID + '.log','r').read():\n",
        "       layout = \"Single\"\n",
        "      else:\n",
        "        !kallisto quant -i $kallisto_index_path_ter -o $RunID --single -l 200 -s 20 -t 2 <(curl -L -r 0-1000000000 -m 600 --speed-limit 1000000 --speed-time 30 $paired 2> $RunID'.log')\n",
        "        if 'curl: (78)' in open(RunID + '.log','r').read():\n",
        "          size = dlsize(RunID)\n",
        "          !rm $RunID\".log\"\n",
        "          print(RunID + '[i=' + str(i) + ']: File not found. Download aborted.')\n",
        "          layout = \"N/A\"\n",
        "          status = \"File not found\"\n",
        "          kallisto_end = time.time()\n",
        "          break\n",
        "        layout = \"Paired\"\n",
        "    kallisto_end = time.time()\n",
        "\n",
        "    #check for stderr logs, if absent, first 1GB file download is complete\n",
        "    size = dlsize(RunID)\n",
        "    if 'curl: (28)' not in open(RunID + '.log','r').read(): #if no slow dl speed error, acccept \n",
        "      !rm $RunID\".log\"\n",
        "      status = \"Downloaded\"\n",
        "      print(RunID + '[i=' + str(i) + ']: Download speed/time is acceptable.')\n",
        "      break\n",
        "    \n",
        "    if RunID + '.log' in os.listdir(execution_dir_path): #remove stderr log file before contining to the next attempt of download\n",
        "      !cp $RunID\".log\" $RunID\"_copy.log\"\n",
        "      !rm $RunID\".log\"\n",
        "      status = \"Download speed/time not accepted\"\n",
        "      print(RunID + '[i=' + str(i) + ']: Download speed/time is not accepted.')\n",
        "  \n",
        "  #If download still incomplete, use the last file saved\n",
        "  kallisto_time = round(kallisto_end - kallisto_start, 4)\n",
        "  \n",
        "  return kallisto_time, layout, status, size, timestamp\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def get_ListOfRunID(RunTablePath):\n",
        "  with open(RunTablePath,\"r\") as RunTable:\n",
        "    ListOfRunID = [RunID.strip().upper() for RunID in RunTable.readlines()]\n",
        "  if \"RUNID\" in ListOfRunID[0]: #If input file has header, exclude header\n",
        "    ListOfRunID = ListOfRunID[1:]\n",
        "  return ListOfRunID\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def open_download_report():\n",
        "  with open(download_report_name, \"r\") as download_report:\n",
        "    download_lines = download_report.readlines()\n",
        "  download_entries = [line.strip().split(\"\\t\") for line in download_lines]\n",
        "\n",
        "  return download_lines, download_entries\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def get_comments_index(download_lines):\n",
        "  hex_line_indices = [download_lines.index(line) for line in download_lines if \"#\" in line]\n",
        "  started_indices = [index for index in hex_line_indices if \"started\" in download_lines[index]]\n",
        "  completed_indices = [index for index in hex_line_indices if \"completed\" in download_lines[index]]\n",
        "\n",
        "  return hex_line_indices, started_indices, completed_indices\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def get_failed_RunID(mode_type):\n",
        "  '''\n",
        "  Opens Download Report;\n",
        "  Collate failed RunIDs from the latest COMPLETED j loop.\n",
        "  '''\n",
        "  if mode_type == \"A\": #CALLED WHEN MOVING ON TO THE NEXT J LOOP\n",
        "    started_index = -1\n",
        "  elif mode_type == \"B\": #CALLED WHEN REDOWNLOADING (j=1 or 2) WITH MODE B\n",
        "    started_index = -2\n",
        "  #Need to reopen download report to compile failed RunIDs\n",
        "  download_lines, download_entries = open_download_report()\n",
        "  hex_line_indices, started_indices, completed_indices = get_comments_index(download_lines)\n",
        "  \n",
        "  j_head_index = started_indices[started_index] # If 1<=j<=2, then 2<=len(started_indices)<=3\n",
        "\n",
        "  # Find failed RunIDs within last completed j loop, in chronological order\n",
        "  list_of_failed_RunID = []\n",
        "  for index in range(j_head_index, completed_indices[-1]):\n",
        "    if index not in hex_line_indices and download_entries[index][2] == \"Download speed/time not accepted\":\n",
        "      list_of_failed_RunID.append(download_entries[index][0])\n",
        "\n",
        "  return list_of_failed_RunID\n",
        "\n",
        "######################################################################\n",
        "\n",
        "\n",
        "def get_j():\n",
        "  '''\n",
        "  Get the current j loop download was paused at.\n",
        "  '''\n",
        "  download_lines, download_entries = open_download_report()\n",
        "  hex_line_indices, started_indices, completed_indices = get_comments_index(download_lines)\n",
        "  j = len(completed_indices)\n",
        "  return j\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def get_RunID_start(RunID_queue):\n",
        "  '''\n",
        "  * CALLED ONCE WHEN REDOWNLOADING WITH MODE B ONLY *\n",
        "\n",
        "  Checks from the bottom of Download Report upwards until the lastest #start.\n",
        "  Takes the latest RunID.\n",
        "  RunID_start_index will be the index of the next RunID in RunID_queue.\n",
        "  If all RunID in queue completed, index will simply = to len(RunID_queue),\n",
        "  will move on to next j loop\n",
        "  '''\n",
        "  download_lines, download_entries = open_download_report()\n",
        "  hex_line_indices, started_indices, completed_indices = get_comments_index(download_lines)\n",
        "\n",
        "  for i in range((len(download_entries) - 1), (started_indices[-1]), -1):\n",
        "    if i not in hex_line_indices:\n",
        "      RunID_latest = download_entries[i][0]\n",
        "      break\n",
        "\n",
        "  try:\n",
        "    RunID_start_index = RunID_queue.index(RunID_latest) + 1\n",
        "  except:\n",
        "    RunID_start_index = 0 # len(RunID_queue) will also be 0, move on to next j loop. \n",
        "    print(\"No RunID_start_index generated.\")\n",
        "\n",
        "  return RunID_start_index\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def update_download_report(to_print):\n",
        "  with open(download_report_name, \"a+\") as download_report:\n",
        "    download_report.write(to_print)\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def json_extract(RunID_file_path):\n",
        "  \"\"\"(str)->(str,str,str,str,str)\n",
        "  Extracts info from run_info.json\n",
        "  \"\"\"\n",
        "  kal_json = ast.literal_eval(open(RunID_file_path + \"run_info.json\", \"r\").read())\n",
        "  n_processed = str(kal_json[\"n_processed\"])\n",
        "  n_pseudoaligned = str(kal_json[\"n_pseudoaligned\"])\n",
        "  p_pseudoaligned = str(kal_json[\"p_pseudoaligned\"])\n",
        "  return n_processed, n_pseudoaligned, p_pseudoaligned\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def abundance(RunID_file_path):\n",
        "  \"\"\"(str)->(str)\n",
        "  Computes percentage of genes mapped\n",
        "  \"\"\"\n",
        "  with open(RunID_file_path + \"abundance.tsv\", \"r\") as abun:\n",
        "    abun.readline()\n",
        "    tpmlist = [line.strip(\"\\n\").split(\"\\t\")[-1] for line in abun.readlines()]\n",
        "    tpmval = [val for val in tpmlist if val != \"0\" and val != \"-nan\"]\n",
        "    return str(round((len(tpmval)/len(tpmlist))*100 , 1)) + \"%\"\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def download_loop(RunID_start_index, RunID_queue):\n",
        "  '''\n",
        "  Execute inner download_loop i=3 for all RunIDs in RunID_queue;\n",
        "  Updates download report as each RunID is processed.\n",
        "  '''\n",
        "  for index in range(RunID_start_index, len(RunID_queue)):\n",
        "    RunID = RunID_queue[index]\n",
        "    print()\n",
        "    print(\"-\"*40)\n",
        "    print()\n",
        "    job_queue = index + 1\n",
        "    total_queue = len(RunID_queue)\n",
        "    print('Processing ' + str(job_queue) + \"/\" + str(total_queue) + \": \" + RunID)\n",
        "\n",
        "    RunID_file_path = execution_dir_path + RunID + \"/\"\n",
        "    if os.path.exists(RunID_file_path) == False:\n",
        "      os.mkdir(RunID_file_path) #Directory to store kallisto files of each RunID\n",
        "    download_status = [RunID, \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\"]\n",
        "    '''\n",
        "    *Download Report Headers*\n",
        "    Run ID | Library Layout | Status | File size | Timestamp | Kallisto time(s) | n_processed | n_pseudoaligned | p_pseudoaligned | %genes mapped\n",
        "\n",
        "    *Possible output for \"Method\"*\n",
        "    download_status[2]\n",
        "      \"N/A\" -> No streaming attempted yet\n",
        "      \"Downloaded\" -> Successfully streamed and quantify single/paired-end data\n",
        "      \"File not found\" -> FASTQ file not found on server\n",
        "      \"Download speed/time not accepted\" -> Failed to stream at a satisfactory speed\n",
        "    '''\n",
        "    #Streaming method\n",
        "    kallisto_time, layout, status, size, timestamp = kallisto_stream(RunID)\n",
        "    if os.path.exists(RunID_file_path + \"run_info.json\"):\n",
        "      download_status[1] = layout\n",
        "      download_status[2] = status\n",
        "      download_status[3] = size\n",
        "      download_status[4] = str(timestamp)\n",
        "      download_status[5] = str(kallisto_time)\n",
        "      n_processed, n_pseudoaligned, p_pseudoaligned = json_extract(RunID_file_path)\n",
        "      download_status[6] = n_processed\n",
        "      download_status[7] = n_pseudoaligned\n",
        "      download_status[8] = p_pseudoaligned\n",
        "      download_status[9] = abundance(RunID_file_path)\n",
        "\n",
        "    else:\n",
        "      print(RunID + \": Missing kallisto output\")\n",
        "\n",
        "    update_download_report(\"\\t\".join(download_status) + \"\\n\")\n",
        "\n",
        "  return True\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def stringS(col, val):\n",
        "  collist = [7, 12, 10,16]\n",
        "  length = collist[col] - len(str(val))\n",
        "  return int(length/2)*\" \"+str(val)+round(length/2)*\" \"+\"|\"\n",
        "\n",
        "######################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flsp_U1UOefU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ListOfRunID = get_ListOfRunID(RunTablePath)\n",
        "\n",
        "# Specify variables for mode A or B\n",
        "\n",
        "if download_mode == \"A\":\n",
        "  j, RunID_start_index = 0, 0\n",
        "  RunID_queue = ListOfRunID\n",
        "\n",
        "elif download_mode == \"B\":\n",
        "  j = get_j()\n",
        "\n",
        "  if j == 3:\n",
        "    RunID_queue = [] #End download. j loop completed thrice.\n",
        "  else:\n",
        "    if j == 0:\n",
        "      RunID_queue = ListOfRunID\n",
        "    elif 1 <= j <= 2:\n",
        "      RunID_queue = get_failed_RunID(download_mode)\n",
        "    if RunID_queue == []: # End j loop if no more failed RunID.\n",
        "      j = 3\n",
        "  \n",
        "  RunID_start_index = get_RunID_start(RunID_queue)\n",
        "  update_download_report(\"#Download resumed\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N8rT19wtaNU",
        "colab_type": "text"
      },
      "source": [
        "####Download Loop\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT92KxG7EuIH",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Code for Download Loop\n",
        "\n",
        "# Loop through j x i times down the RunID_queue\n",
        "\n",
        "for loop in range(j,3):\n",
        "  print(\"\\n\" + \"-\"*40 + \"\\n\")\n",
        "  if RunID_start_index == 0:\n",
        "    print(\"Download attempt %s\"%(loop+1))\n",
        "    update_download_report(\"#Download attempt %s started\\n\" % (loop+1))\n",
        "  else:\n",
        "    print(\"Download attempt %s resumed\"%(j+1))\n",
        "  \n",
        "  download_loop(RunID_start_index, RunID_queue)\n",
        "  update_download_report(\"#Download attempt %s completed\\n\" % (loop+1))\n",
        "\n",
        "  #Reset RunID_start_index and RunID_queue\n",
        "  RunID_start_index = 0\n",
        "  RunID_queue = get_failed_RunID(\"A\")\n",
        "  if RunID_queue == []: # End j loop if no more failed RunID.\n",
        "      print(\"All RunIDs have been successfully downloaded.\")\n",
        "      break\n",
        "print(\"Download complete.\")\n",
        "with open(download_report_name, \"r\") as download_report:\n",
        "  file_content = download_report.read()\n",
        "  file_error = [(a.start(),a.end()) for a in list(re.finditer('File not found', file_content))]\n",
        "  file_success = [(a.start(),a.end()) for a in list(re.finditer('Downloaded', file_content))]\n",
        "  print(\"| Total | Downloaded | Rejected | File not found |\\n|\"\\\n",
        "        + stringS(0,len(get_ListOfRunID(RunTablePath)))\\\n",
        "        + stringS(1,len(file_success))\\\n",
        "        + stringS(2,len(get_ListOfRunID(RunTablePath))-len(file_success)-len(file_error))\\\n",
        "        + stringS(3,len(file_error)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}